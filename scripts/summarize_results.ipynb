{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Select an Interpreter to start Jupyter\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=$PWD\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from domainbed.lib import misc, reporting\n",
    "from domainbed.lib.query import Q\n",
    "from domainbed import model_selection\n",
    "from domainbed import datasets\n",
    "\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from domainbed.scripts.collect_results import print_table, format_mean\n",
    "# from domainbed.lib.query import make_selector_fn\n",
    "\n",
    "import scipy\n",
    "latex = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def load_records(path, file_name):\n",
    "    records = []\n",
    "    for i, subdir in tqdm.tqdm(list(enumerate(os.listdir(path))),\n",
    "                               ncols=80,\n",
    "                               leave=False):\n",
    "        results_path = os.path.join(path, subdir, file_name)\n",
    "        try:\n",
    "            with open(results_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    records.append(json.loads(line[:-1]))\n",
    "        except IOError:\n",
    "            pass\n",
    "\n",
    "    return Q(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouped_records(records, group_str):\n",
    "    \"\"\"Group records by (trial_seed, dataset, algorithm, test_env). Because\n",
    "    records can have multiple test envs, a given record may appear in more than\n",
    "    one group.\"\"\"\n",
    "    result = collections.defaultdict(lambda: [])\n",
    "    for r in records:\n",
    "        for test_env in r[\"args\"][\"test_envs\"]:\n",
    "            group = list(Q([r]).select(group_str)[0])\n",
    "            group.append(test_env)\n",
    "            group = tuple(group)\n",
    "            result[group].append(r)\n",
    "    group_key = group_str.replace(' ', '').replace('args.','').replace('hparams.', '').split(',') + ['test_env', 'records']\n",
    "    \n",
    "    grouped_records = []\n",
    "    for v, r in result.items():\n",
    "        v = list(v)\n",
    "        v.append(Q(r))\n",
    "        grouped_records.append(dict(zip(group_key, v)))\n",
    "    return Q(grouped_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_print_table(table, header_text, row_labels, col_labels, colwidth=10,\n",
    "    latex=True):\n",
    "    \"\"\"Pretty-print a 2D array of data, optionally with row/col labels\"\"\"\n",
    "    print(\"\")\n",
    "\n",
    "    if latex:\n",
    "        num_cols = len(table[0])\n",
    "        \"\"\"\n",
    "        print(\"\\\\begin{center}\")\n",
    "        print(\"\\\\adjustbox{max width=\\\\textwidth}{%\")\n",
    "        print(\"\\\\begin{tabular}{l\" + \"c\" * num_cols + \"}\")\n",
    "        print(\"\\\\toprule\")\n",
    "        \"\"\"\n",
    "    else:\n",
    "        print(\"--------\", header_text)\n",
    "\n",
    "    for row, label in zip(table, row_labels):\n",
    "        row.insert(0, label)\n",
    "    \n",
    "    \"\"\"\n",
    "    if latex:\n",
    "        col_labels = [\"\\\\textbf{\" + str(col_label).replace(\"%\", \"\\\\%\") + \"}\"\n",
    "            for col_label in col_labels]\n",
    "    table.insert(0, col_labels)\n",
    "    \"\"\"\n",
    "\n",
    "    for r, row in enumerate(table):\n",
    "        misc.print_row(row, colwidth=colwidth, latex=latex)\n",
    "        \"\"\"\n",
    "        if latex and r == 0:\n",
    "            print(\"\\\\midrule\")\n",
    "        \"\"\"\n",
    "    print(\"\\\\midrule\")\n",
    "    \"\"\"\n",
    "    if latex:\n",
    "        print(\"\\\\bottomrule\")\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms = ['FrozenERM']\n",
    "# algorithms = ['ERM', 'CORAL', 'DANN', 'APCLIP', 'CLIP', 'WordCLIP']\n",
    "# algorithms = ['ERM', 'CORAL']\n",
    "algorithms = ['ERM']\n",
    "# algorithms = ['APCLIP']\n",
    "backbones = ['clip_vitb16']\n",
    "clip_backbones = ['ViT-B/16']\n",
    "hparams = ['{\"backbone\": \"clip\", \"clip_backbone\": \"ViT-B/16\"}', '{\"backbone\": \"clip\", \"clip_backbone\": \"ViT-B/32\"}','{\"backbone\": \"clip\", \"clip_backbone\": \"RN101\"}']\n",
    "# backbones = ['DeiT', 'HViT', 'ViT-B32', 'ViT-B16','resnet50', 'resnet18']\n",
    "tgt_dataset_names = ['VLCS', 'PACS', 'OfficeHome', 'TerraIncognita']\n",
    "tgt_adaptation_names = ['None', 'T3A-64', 'TentClf-64', 'SHOTIM-64', 'PLClf-64', 'SHOT-64', 'PseudoLabel-64']\n",
    "# tgt_adaptation_names = ['None']\n",
    "seeds = [0, 1, 2]\n",
    "records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "### Backbone == clip\n",
    "### clip_backbone == 'ViT-B/16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████▏                    | 3209/6874 [01:32<02:56, 20.71it/s]"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    r = load_records('/groups/gcb50389/xinzhang/t3a/{}'.format(backbone), 'results.jsonl')\n",
    "    r = r.filter_in('args.trial_seed', seeds)\n",
    "    r = r.filter_in('args.algorithm', algorithms)\n",
    "    r = r.filter_in('args.hparams', hparams)\n",
    "    r = r.map(lambda r: {**r, \"adapt\": 'None', \"selection_method\": model_selection.IIDAccuracySelectionMethod}) \n",
    "    records += r._list\n",
    "\n",
    "    for tgt_adaptation in tgt_adaptation_names:\n",
    "        r = load_records('/groups/gcb50389/xinzhang/t3a/{}'.format(backbone), 'results_{}.jsonl'.format(tgt_adaptation))\n",
    "        r = r.filter_in('args.trial_seed', seeds)\n",
    "        r = r.filter_in('args.algorithm', algorithms)\n",
    "        # r = r.filter_equals('filter_K', 100)\n",
    "        r = r.map(lambda r: {**r, \"adapt\": r['args']['adapt_algorithm'], \"selection_method\": model_selection.IIDAccuracySelectionMethod}) \n",
    "        records += r._list\n",
    "records = Q(records)\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaptation_names:  ['None']\n",
      "dataset_names:  ['VLCS', 'PACS', 'OfficeHome', 'TerraIncognita']\n"
     ]
    }
   ],
   "source": [
    "# perpare the.\n",
    "selection_method = model_selection.IIDAccuracySelectionMethod\n",
    "group_str = 'args.trial_seed, args.dataset, args.algorithm, hparams.backbone, adapt'\n",
    "grouped_records = get_grouped_records(records, group_str).map(lambda group:\n",
    "        { **group, \"sweep_acc\": group[\"records\"][0]['selection_method'].sweep_acc(group[\"records\"]) }\n",
    "    ).filter(lambda g: g[\"sweep_acc\"] is not None)\n",
    "\n",
    "adaptation_names = Q(records).select(\"adapt\").unique()\n",
    "dataset_names = Q(records).select(\"args.dataset\").unique().sorted()\n",
    "dataset_names = [d for d in datasets.DATASETS if d in dataset_names]\n",
    "print('adaptation_names: ', adaptation_names)\n",
    "print('dataset_names: ', dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clip']\n",
      "['TerraIncognita']\n",
      "\n",
      "\\subsubsection{TerraIncognita}\n",
      "\n",
      "\\begin{center}\n",
      "\\adjustbox{max width=\\textwidth}{%\n",
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      "\\textbf{Backbone}    & \\textbf{L100}        & \\textbf{L38}         & \\textbf{L43}         & \\textbf{L46}         & \\textbf{Avg}         \\\\\n",
      "\\midrule\n",
      "clip                 & 49.3 $\\pm$ 8.7       & 36.2 $\\pm$ 3.3       & 42.8 $\\pm$ 3.2       & 36.6 $\\pm$ 2.0       & 41.2                 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "backbone_names = Q(records).select(\"backbone\").unique()\n",
    "# alg_names = ([n for n in algorithms.ALGORITHMS if n in alg_names] +\n",
    "#     [n for n in alg_names if n not in algorithms.ALGORITHMS])\n",
    "print(backbone_names)\n",
    "# # read dataset names and sort (lexicographic order)\n",
    "dataset_names = Q(records).select(\"dataset\").unique().sorted()\n",
    "print(dataset_names)\n",
    "dataset_names = [d for d in datasets.DATASETS if d in dataset_names]\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    if latex:\n",
    "        print()\n",
    "        print(\"\\\\subsubsection{{{}}}\".format(dataset))\n",
    "    test_envs = range(datasets.num_environments(dataset))\n",
    "\n",
    "    table = [[None for _ in [*test_envs, \"Avg\"]] for _ in backbone_names]\n",
    "    for i, backbone in enumerate(backbone_names):\n",
    "        means = []\n",
    "        for j, test_env in enumerate(test_envs):\n",
    "            trial_accs = (grouped_records\n",
    "                .filter_equals(\n",
    "                    \"dataset, backbone, test_env\",\n",
    "                    (dataset, backbone, test_env)\n",
    "                ).select(\"sweep_acc\"))\n",
    "            mean, err, table[i][j] = format_mean(trial_accs, latex)\n",
    "            means.append(mean)\n",
    "        if None in means:\n",
    "            table[i][-1] = \"X\"\n",
    "        else:\n",
    "            table[i][-1] = \"{:.1f}\".format(sum(means) / len(means))\n",
    "\n",
    "    col_labels = [\n",
    "        \"Backbone\", \n",
    "        *datasets.get_dataset_class(dataset).ENVIRONMENTS,\n",
    "        \"Avg\"\n",
    "    ]\n",
    "    header_text = (f\"Dataset: {dataset}, \"\n",
    "        f\"model selection method: {selection_method.name}\")\n",
    "    print_table(table, header_text, backbone_names, list(col_labels),\n",
    "        colwidth=20, latex=latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish backbone:  ERM VLCS 12 clip\n",
      "Finish backbone:  ERM PACS 12 clip\n",
      "Finish backbone:  ERM OfficeHome 12 clip\n",
      "Finish backbone:  ERM TerraIncognita 12 clip\n",
      "Did not finish, ERROR!!!!! 0 CORAL VLCS clip\n",
      "Did not finish, ERROR!!!!! 4 CORAL PACS clip\n",
      "Finish backbone:  CORAL OfficeHome 12 clip\n",
      "Finish backbone:  CORAL TerraIncognita 12 clip\n"
     ]
    }
   ],
   "source": [
    "# def check_records(records):\n",
    "#     for rec in records:\n",
    "#         for r in rec['records']:\n",
    "#             print(r)\n",
    "#         # assert len(rec) == 360\n",
    "\n",
    "# # Check the data missing.\n",
    "# # if len() == 60 : backbone + 4 tta methods. \n",
    "# # elif: len() == 12 : backbone only. \n",
    "# else: ERROR.\n",
    "for backbone in backbones:\n",
    "    for algo in algorithms:\n",
    "        for dataset in dataset_names:\n",
    "            records = grouped_records.filter_equals(\"dataset, algorithm, backbone\", (dataset, algo, backbone))\n",
    "            if len(records) == 84:\n",
    "                print('Finish all experiment: backbone + 6 TTA methods', algo, dataset, len(records), backbone)\n",
    "                # check_records(records)\n",
    "            elif len(records) == 12:\n",
    "                print('Finish backbone: ', algo, dataset, len(records), backbone)\n",
    "            else:\n",
    "                print('Did not finish, ERROR!!!!!', len(records), algo, dataset, backbone)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# # for algo in algorithms:\n",
    "# d = {}\n",
    "# for dataset in dataset_names:\n",
    "#     recoreds = grouped_records.filter_equals(\"dataset, algorithm\", (dataset, 'D'))\n",
    "#     # assert  == 'DANN':\n",
    "#     if len(recoreds) != 60:\n",
    "#         print(len(recoreds), 'DANN', dataset)\n",
    "#         for rec in recoreds:\n",
    "#             print(len(rec['records']))\n",
    "#             for r in rec['records']:\n",
    "#                 assert r['args']['algorithm'] == 'DANN'\n",
    "#                 print(r['args']['output_dir'])\n",
    "#                 dir = r['args']['output_dir']\n",
    "#                 try:\n",
    "#                     shutil.rmtree(dir)\n",
    "#                     print(dir)\n",
    "#                 except:\n",
    "#                     pass\n",
    "    # print(len(grouped_records[0]['records']))\n",
    "    # print(grouped_records[0]['output_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip\n",
      "\n",
      "ERM                       & 80.8 $\\pm$ 0.4            & 93.0 $\\pm$ 0.7            & 77.3 $\\pm$ 1.6            & 42.2 $\\pm$ 5.5            & 73.4                      \\\\\n",
      "\\midrule\n",
      "\n",
      "CORAL                     & X                         & 87.4 $\\pm$ 0.0            & 77.5 $\\pm$ 1.0            & 40.3 $\\pm$ 4.4            & X                         \\\\\n",
      "\\midrule\n"
     ]
    }
   ],
   "source": [
    "for backbone in backbones:\n",
    "    print(backbone)\n",
    "    for algorithm in algorithms:\n",
    "        table = [[None for _ in [*dataset_names, \"Avg\"]] for _ in adaptation_names]\n",
    "        model_names = []\n",
    "        for i, adapt_method in enumerate(adaptation_names):\n",
    "            means = []\n",
    "            if i == 0:\n",
    "                model_names.append(algorithm)\n",
    "            else:\n",
    "                model_names.append('+'+adapt_method)\n",
    "            for j, dataset in enumerate(dataset_names):\n",
    "                trial_averages = (grouped_records\n",
    "                    .filter_equals(\n",
    "                        \"dataset, adapt, backbone, algorithm\",\n",
    "                        (dataset, adapt_method, backbone, algorithm)\n",
    "                    ).group(\"trial_seed\")\n",
    "                    .map(lambda trial_seed, group:\n",
    "                        group.select(\"sweep_acc\").mean()\n",
    "                    )\n",
    "                )\n",
    "                mean, err, table[i][j] = format_mean(trial_averages, latex)\n",
    "                means.append(mean)\n",
    "            if None in means:\n",
    "                table[i][-1] = \"X\"\n",
    "            else:\n",
    "                table[i][-1] = \"{:.1f}\".format(sum(means) / len(means))\n",
    "                a = grouped_records.filter_equals(\"adapt, backbone, algorithm\", ('None', backbone, algorithm)).filter_in('dataset', tgt_dataset_names).select('sweep_acc')\n",
    "                b = grouped_records.filter_equals(\"adapt, backbone, algorithm\", (adapt_method, backbone, algorithm)).filter_in('dataset', tgt_dataset_names).select('sweep_acc')\n",
    "                if (len(a) == len(b) == 48) & (i != 0):\n",
    "                    p_val = scipy.stats.ttest_rel(a, b, alternative='less')[1]\n",
    "                    if p_val <= 0.01:\n",
    "                        table[i][-1] += '$^{**}$'\n",
    "                    elif p_val <= 0.05:\n",
    "                        table[i][-1] += '$^{*}$'\n",
    "                else:\n",
    "                    # print(len(a), len(b))\n",
    "                    pass \n",
    "        # for i, adapt_method in enumerate(adaptation_names):\n",
    "        #     for j, dataset in enumerate(dataset_names):\n",
    "        #         try:\n",
    "        #             val = float(table[i][j].split(' ')[0])\n",
    "        #             base_val = float(table[0][j].split(' ')[0])\n",
    "        #             if val > base_val:\n",
    "        #                 table[i][j] = '\\\\textbf{' + table[i][j] + '}'\n",
    "        #         except:\n",
    "        #             pass\n",
    "\n",
    "        col_labels = [\"Models\", *dataset_names, \"Avg\"]\n",
    "        header_text = f\"Averages, backbone: {algorithm}\"\n",
    "        custom_print_table(table, header_text, model_names, col_labels, colwidth=25,\n",
    "            latex=latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-aa333b05ca61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackbone_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"args.hparams.backbone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# alg_names = ([n for n in algorithms.ALGORITHMS if n in alg_names] +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     [n for n in alg_names if n not in algorithms.ALGORITHMS])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# read dataset names and sort (lexicographic order)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/T3A/domainbed/lib/query.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, selector)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_selector_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/T3A/domainbed/lib/query.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_selector_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/T3A/domainbed/lib/query.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpart_selectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/T3A/domainbed/lib/query.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'args'"
     ]
    }
   ],
   "source": [
    "backbone_names = Q(records).select(\"args.hparams.backbone\").unique()\n",
    "# alg_names = ([n for n in algorithms.ALGORITHMS if n in alg_names] +\n",
    "#     [n for n in alg_names if n not in algorithms.ALGORITHMS])\n",
    "print(backbone_names)\n",
    "# read dataset names and sort (lexicographic order)\n",
    "dataset_names = Q(records).select(\"args.dataset\").unique().sorted()\n",
    "dataset_names = [d for d in datasets.DATASETS if d in dataset_names]\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    if latex:\n",
    "        print()\n",
    "        print(\"\\\\subsubsection{{{}}}\".format(dataset))\n",
    "    test_envs = range(datasets.num_environments(dataset))\n",
    "\n",
    "    table = [[None for _ in [*test_envs, \"Avg\"]] for _ in backbone_names]\n",
    "    for i, backbone in enumerate(backbone_names):\n",
    "        means = []\n",
    "        for j, test_env in enumerate(test_envs):\n",
    "            trial_accs = (grouped_records\n",
    "                .filter_equals(\n",
    "                    \"dataset, backbone, test_env\",\n",
    "                    (dataset, backbone, test_env)\n",
    "                ).select(\"sweep_acc\"))\n",
    "            mean, err, table[i][j] = format_mean(trial_accs, latex)\n",
    "            means.append(mean)\n",
    "        if None in means:\n",
    "            table[i][-1] = \"X\"\n",
    "        else:\n",
    "            table[i][-1] = \"{:.1f}\".format(sum(means) / len(means))\n",
    "\n",
    "    col_labels = [\n",
    "        \"Backbone\", \n",
    "        *datasets.get_dataset_class(dataset).ENVIRONMENTS,\n",
    "        \"Avg\"\n",
    "    ]\n",
    "    header_text = (f\"Dataset: {dataset}, \"\n",
    "        f\"model selection method: {selection_method.name}\")\n",
    "    print_table(table, header_text, backbone_names, list(col_labels),\n",
    "        colwidth=20, latex=latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4608eae2835f79d5a53bc6b12e0a66da51d562043bb25a91ae21208ab2cf5c0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
